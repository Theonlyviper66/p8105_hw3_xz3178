---
title: "HW3"
author: "Xuesen Zhao"
date: "2022-10-08"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(ggridges)
library(patchwork)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%"
)

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```


```{r}
library(p8105.datasets)
data("instacart")
```

The instacart data set is stored as a dataframe that contains `r nrow(instacart)` rows and `r ncol(instacart)` columns, where each row is a product from an order. Some examples of the variables include add_to_cart_order which is the order in which each product is added to the cart, order sequence number for the user, order_dow which is the day of the week on which the order was placed, the name of the product, aisle identified, etc. The head of the data set is shown below: 

```{r}
head(instacart,n=4L)
```

```{r}
instacart %>% 
  group_by(aisle_id,aisle) %>%
  summarize(
    n_aisle = n(),
  ) %>% arrange(desc(n_aisle))
```

There are a total of 134 aisles. Most items are ordered from the fresh vegetables (#83) aisle. 

```{r}
instacart %>% 
  count(aisle) %>% 
  filter(n > 10000) %>% 
  mutate(aisle = fct_reorder(aisle, n)) %>% 
  ggplot(aes(x = aisle, y = n)) + 
  geom_point() + 
  labs(title = "Number of items ordered in each aisle") +
  theme(axis.text.x = element_text(angle = 60, hjust = 1))
```

The following table shows the three most popular items in the aisles "baking ingredients", "dog food care", and "packaged vegetables":

```{r}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>%
  group_by(aisle) %>% 
  count(product_name) %>% 
  mutate(rank = min_rank(desc(n))) %>% 
  filter(rank < 4) %>% 
  arrange(desc(n)) %>%
  knitr::kable()
  
```


The following tables shows the mean hour of the day at which Pink Lady Apples and Coffee Ice Cream are ordered on each day of the week:

```{r}
instacart %>%
  filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>%
  group_by(product_name, order_dow) %>%
  summarize(mean_hour = mean(order_hour_of_day)) %>%
  spread(key = order_dow, value = mean_hour) %>%
  knitr::kable(digits = 2)
```

## Question 2

```{r}
accel = read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>% 
  mutate(
    weekday_weekend = ifelse(day %in% c("Monday","Tuesday","Wednesday","Thursday","Friday"),"weekday","weekend"),
    weekday_weekend = as.factor(weekday_weekend)
  )
  
```

A weekday_weekend variable was added to the original data set to indicate if that day is a weekday or a weekend day, and the resulting data set contains `r nrow(accel)` rows and `r ncol(accel)` columns.  It includes variable such as the week number, which day of the week it is, and the activity counts for each minute of a 24-hour day starting at midnight. 

The following table shows the total activities for each day, as specified by which week it was in and which day of the week it was:

```{r}
accel %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity",
    values_to = "activity_count"
  ) %>% 
  group_by(week,day) %>%
  summarize(day_sum = sum(activity_count)) %>% 
  pivot_wider(
    names_from = "day",
    values_from = "day_sum"
  ) %>% 
  select(Monday,Tuesday,Wednesday,Thursday,Friday,Saturday,Sunday) %>%
  knitr::kable()
```

As shown in the above table, there had not been a consistent trend over the 5 weeks. Nevertheless, there were certain trend within each week. For week 1 and 2, the total activities of each day gradually increased until it peaked on either Sunday or Saturday. For week 3, the total activities of each day started with the highest on Monday, and fluctuated over the remaining of the week. For week 4 and 5, the total activities on both Saturdays were extremely low, and the overall activities of weekend was also much lower compared to that of the weekdays. 

```{r}
accel %>%
  mutate(
    day=factor(day,levels = c("Monday", "Tuesday", "Wednesday","Thursday","Friday","Saturday","Sunday"))
    )%>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "activity",
    values_to = "activity_count"
  ) %>% 
  group_by(day_id,day) %>%
  summarize(day_sum = sum(activity_count)) %>%
  ggplot(aes(x=day_id,y=day_sum))+geom_line(aes(color=day))+labs(title="Figure 2.1: Total activities by days")
```

For most days of a week except for Sunday, the total activities were increasing before day 10. For Monday, Saturday, and Sunday, the total activities started to decrease after it reached its peak values. For Tuesday, Thursday, and Friday, the total activities started to increase again after reaching the minimum value. The change of total activities for each Wednesday over these weeks was more gradual. 


## Question 3

```{r}
library(p8105.datasets)
data("ny_noaa")
```

The original data set ny_noaa contains `r nrow(ny_noaa)` rows and `r ncol(ny_noaa)` columns which is stored as a tibble/dataframe. The data set contains information on the date, ID for the New York state weather stations, and 5 core weather variables including precipitation (tenths of mm), snowfall (mm), snow depth (mm), maximum temperature and minimum temperature in tenths of degree C. `r scales::percent(mean(is.na(ny_noaa))) ` of the original data set has missing values, which constituted a relatively large proportion.

```{r}
ny_noaa %>%
  janitor::clean_names() %>%
  separate(date, into = c("year","month","day"),sep = "-") %>%
  mutate(
    prcp = prcp / 10,
    tmax = as.numeric(tmax) / 10,
    tmin = as.numeric(tmin) / 10,
    snow = snow / 10
  ) %>% 
  group_by(snow) %>%
  summarize(
    n_snow = n()
  ) %>% 
  arrange(desc(n_snow))
```

The maximum and minimum temperature were divided by 10 to give a unit of degree Celsius. Precipitation values were also divided by 10 to give a unit of mm instead of tenths of mm for better interpretability. Snowfall was also divided by 10 to give a unit of cm. The most commonly observed value for snowfall is 0 cm. It makes sense because for most of the time there is no snow. 

```{r}
ny_noaa_clean = ny_noaa %>%
  separate(date, into = c("year","month","day"),sep = "-") %>%
  mutate(
    prcp = prcp / 10,
    tmax = as.numeric(tmax) / 10,
    tmin = as.numeric(tmin) / 10,
    snow = snow / 10,
    month=month.abb[as.numeric(month)]
  ) 


ny_noaa_clean %>%
  mutate(
    year = as.numeric(year)
  ) %>%
  filter(month=="Jan"|month=="Jul") %>%
  group_by(year,id,month) %>%
  summarize( 
    mean_tmax = mean(tmax)
  ) %>%
  ggplot(aes(x=year,y=mean_tmax,group=id))+geom_line()+labs(title = "Figure 3.1: Mean tmax in January and July \n for each station across years ",x="year", y ="mean tmax (degrees C)")+facet_grid(. ~ month)
```

Figure 3.1 showed the average max temperature in January and July for each station across years, where each line represented a distinct subway station. The temperature fluctuated across years, and the overall temperature for a particular month (either January or July) was contained within a certain range. There was no obvious outliers as shown in the figure. 

```{r}
library(patchwork)
library(hexbin)
q3_fig_i = 
  ny_noaa_clean %>%
  ggplot(aes(x=tmin,y=tmax))+geom_hex()+labs(title = "Figure 3.2: tmax vs. tmin",x="tmin (degrees C)", y ="tmax (degrees C)")

q3_fig_ii = 
  ny_noaa_clean %>%
  filter(0<snow & snow<100) %>%
  group_by(year) %>%
  ggplot(aes(x=year,y=snow))+geom_boxplot()+labs(title = "Figure 3.3: Snowfall by year",x="year", y ="snowfall (cm)")+coord_flip()

q3_fig_i + q3_fig_ii
```

Figure 3.2 showed a hex plot of the maximum temperature versus minimum temperature of each observation. Figure 3.3 showed the distribution of snowfall values greater than 0 and less than 10 cm of each year.  

